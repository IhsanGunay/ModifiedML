{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 3 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "from utils import ce_squared, load_imdb, ColoredWeightedDoc\n",
    "from IPython.display import display, display_html\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from classifiers import TransparentMultinomialNB\n",
    "from time import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the imdb reviews data\n",
      "Data loaded.\n",
      "Extracting features from the training dataset using a sparse vectorizer\n",
      "Feature extraction technique is TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None).\n",
      "done in 5.645135164260864s\n",
      "(25000, 27272)\n",
      "n_samples: 25000, n_features: 27272 \n",
      "\n",
      "Extracting features from the test dataset using the same vectorizer\n",
      "done in 5.47081995010376s\n",
      "n_samples: 25000, n_features: 27272 \n",
      "\n",
      "Loading took 12.76s.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "vect = TfidfVectorizer(min_df=5, max_df=1.0, binary=False, ngram_range=(1, 1))\n",
    "\n",
    "X_train, y_train, X_test, y_test, train_corpus, test_corpus = load_imdb(\"./aclImdb\", shuffle=True, vectorizer=vect)\n",
    "\n",
    "feature_names = vect.get_feature_names()\n",
    "y_test_na = y_test[:, np.newaxis]\n",
    "y_test_na = np.append(y_test_na, 1-y_test_na, axis=1)\n",
    "y_modified = np.copy(y_train)\n",
    "\n",
    "duration = time() - t0\n",
    "\n",
    "print(\"Loading took {:0.2f}s.\\n\".format(duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_val = csr_matrix(X_train[12500:])\n",
    "y_val = np.copy(y_train[12500:])\n",
    "\n",
    "X_train = csr_matrix(X_train[:12500])\n",
    "y_train = np.copy(y_train[:12500])\n",
    "\n",
    "y_val_na = y_val[:, np.newaxis]\n",
    "y_val_na = np.append(y_val_na, 1-y_val_na, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('clf4.arch', 'rb') as f:\n",
    "    clf_arch = load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'classifiers.TransparentMultinomialNB'> \n",
      "\n",
      "[1, 8, 2, 9, 3, 10, 4, 5, 6, 7, 8, 9, 10] \n",
      "\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n"
     ]
    }
   ],
   "source": [
    "clf_arch.stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loading the last classifier in the archive\n",
    "ctrl_clf = clf_arch.ctrl_clf\n",
    "best_clf = clf_arch.classifiers[-1]\n",
    "train_indices_set = set(clf_arch.train_indices[-1])\n",
    "train_indices = clf_arch.train_indices[-1]\n",
    "y_modified = np.copy(clf_arch.modified_labels[-1])\n",
    "round_tag = clf_arch.round_tags[-1] + 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples used : 7759\n",
      "Number of labels modified: 465\n"
     ]
    }
   ],
   "source": [
    "print('Number of samples used :', len(train_indices))\n",
    "changed_labels = np.array(list(filter(lambda x: x[0]!=x[1], zip(y_modified[train_indices], y_train[train_indices]))))\n",
    "print('Number of labels modified:', len(changed_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 to 0 : 210\n",
      "0 to 1 : 255\n"
     ]
    }
   ],
   "source": [
    "changes = changed_labels[:,0] - changed_labels[:,1]\n",
    "print('1 to 0 :', len(list(filter(lambda x: x<0, changes))))\n",
    "print('0 to 1 :', len(list(filter(lambda x: x>0, changes))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy is 0.89664\n",
      "Test accuracy is 0.86596\n",
      "Test accuracy is 0.83216\n",
      "Test accuracy is 0.8254\n",
      "Validation accuracy is 0.85568\n"
     ]
    }
   ],
   "source": [
    "val_acc = best_clf.score(X_val, y_val)\n",
    "print('Validation accuracy is {}'.format(val_acc))\n",
    "\n",
    "test_acc = best_clf.score(X_test, y_test)\n",
    "print('Test accuracy is {}'.format(test_acc))\n",
    "\n",
    "clf = TransparentMultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "test_acc = ctrl_clf.score(X_test, y_test)\n",
    "print('Test accuracy is {}'.format(test_acc))\n",
    "\n",
    "test_acc = clf.score(X_test, y_test)\n",
    "print('Test accuracy is {}'.format(test_acc))\n",
    "\n",
    "val_acc = clf.score(X_val, y_val)\n",
    "print('Validation accuracy is {}'.format(val_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Control Classifier<b>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.89      0.84     12500\n",
      "          1       0.87      0.78      0.82     12500\n",
      "\n",
      "avg / total       0.84      0.83      0.83     25000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>Best Classifier<b>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.87      0.87     12500\n",
      "          1       0.87      0.86      0.87     12500\n",
      "\n",
      "avg / total       0.87      0.87      0.87     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_pred = best_clf.predict(X_test)\n",
    "ctrl_pred = ctrl_clf.predict(X_test)\n",
    "display_html(\"<b>\"+'Control Classifier'+\"<b>\", raw=True)\n",
    "print(classification_report(y_test, ctrl_pred))\n",
    "display_html(\"<b>\"+'Best Classifier'+\"<b>\", raw=True)\n",
    "print(classification_report(y_test, best_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Control Classifier<b>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Positive\n",
      "paulie ([  0.0572581   11.62001835]) edie ([ 0.          9.50310828]) antwone ([ 0.          7.72889767]) matthau ([  0.78248313  13.0938614 ]) goldsworthy ([ 0.          6.79732636]) din ([ 0.          6.77401576]) victoria ([  1.0431436   13.36768916]) wonderfully ([  2.47759161  22.57390329]) felix ([ 0.48385479  9.01038775]) gundam ([ 0.19220119  7.0279382 ])\n",
      "\n",
      "Top Negative\n",
      "waste ([ 101.13224211    5.46404149]) worst ([ 145.77726278   10.81685456]) pointless ([ 34.66318443   2.24914225]) seagal ([ 13.48847522   0.32485711]) boll ([ 10.67268495   0.0988785 ]) unfunny ([ 21.58484167   1.14247772]) awful ([ 97.85823623   8.45586203]) mst3k ([ 15.01247428   0.64075814]) unwatchable ([ 10.95370109   0.24189979]) stinker ([ 10.64923928   0.23665215])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>Best Classifier<b>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Positive\n",
      "superb ([  1.10649782  16.6795776 ]) wonderful ([  2.96593022  32.14253751]) amazing ([  2.40158022  24.02243591]) wonderfully ([ 0.22295821  7.67755475]) loved ([  3.21779012  27.36536967]) favorite ([  2.55847621  21.98618713]) fantastic ([  1.86691541  17.22070786]) touching ([ 0.70935884  9.8430855 ]) gem ([ 0.62315025  9.09394098]) refreshing ([ 0.12773228  5.89928259])\n",
      "\n",
      "Top Negative\n",
      "waste ([ 35.53800166   0.48004901]) worst ([ 48.52448864   1.49461174]) awful ([ 33.24351215   0.79430814]) poorly ([ 17.60087299   0.31477437]) pointless ([ 12.93774176   0.23736166]) terrible ([ 28.46097263   1.63882491]) pathetic ([ 11.63340441   0.29058524]) lame ([ 16.20249451   0.87599945]) unfunny ([ 8.08817749  0.        ]) worse ([ 25.26927848   1.99183594])\n"
     ]
    }
   ],
   "source": [
    "best_weights = best_clf.get_weights()\n",
    "ctrl_weights = ctrl_clf.get_weights()\n",
    "\n",
    "best_ws = np.argsort(best_weights)\n",
    "ctrl_ws  = np.argsort(ctrl_weights)\n",
    "\n",
    "display_html(\"<b>\"+'Control Classifier'+\"<b>\", raw=True)\n",
    "\n",
    "print(\"Top Positive\")\n",
    "print(\" \".join([\"{} ({})\".format(feature_names[i], ctrl_clf.feature_count_[:,i])\n",
    "                for i in ctrl_ws[-10:][::-1]]))\n",
    "\n",
    "print(\"\\nTop Negative\")\n",
    "print(\" \".join([\"{} ({})\".format(feature_names[i], ctrl_clf.feature_count_[:,i])\n",
    "                for i in ctrl_ws[:10]]))\n",
    "\n",
    "display_html(\"<b>\"+'Best Classifier'+\"<b>\", raw=True)\n",
    "\n",
    "print(\"Top Positive\")\n",
    "print(\" \".join([\"{} ({})\".format(feature_names[i], best_clf.feature_count_[:,i])\n",
    "                for i in best_ws[-10:][::-1]]))\n",
    "\n",
    "print(\"\\nTop Negative\")\n",
    "print(\" \".join([\"{} ({})\".format(feature_names[i], best_clf.feature_count_[:,i])\n",
    "                for i in best_ws[:10]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27272, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(27272,)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.transpose(X_test[i].todense()).shape)\n",
    "b = np.transpose(best_clf.get_weights()).shape\n",
    "c = np.multiply(a,b)\n",
    "b\n",
    "#c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Probability Matrix<b>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.57250962  0.42749038]\n",
      "[ 0.29450805  0.70549195]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>Control Classifier<b>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size = 1, color=gray> when </font><font size = 1, color=gray> this </font><font size = 1, color=gray> show </font><font size = 1, color=gray> first </font><font size = 1, color=gray> came </font><font size = 1, color=gray> to </font><font size = 1, color=gray> Disney, </font><font size = 1, color=gray> i </font><font size = 1, color=gray> love </font><font size = 1, color=gray> it </font><font size = 1, color=gray> started </font><font size = 1, color=gray> watching </font><font size = 1, color=gray> all </font><font size = 1, color=gray> the </font><font size = 1, color=gray> time. </font><font size = 1, color=gray> It </font><font size = 1, color=gray> quickly </font><font size = 1, color=gray> became </font><font size = 1, color=gray> one </font><font size = 1, color=gray> of </font><font size = 1, color=gray> my </font><font size = 1, color=gray> favorite </font><font size = 1, color=gray> Disney </font><font size = 1, color=gray> shows </font><font size = 1, color=gray> ever </font><font size = 1, color=gray> but </font><font size = 1, color=gray> this </font><font size = 1, color=gray> show </font><font size = 1, color=gray> somehow </font><font size = 1, color=gray> transformed </font><font size = 1, color=gray> into </font><font size = 1, color=gray> something </font><font size = 1, color=gray> that </font><font size = 1, color=gray> is </font><font size = 1, color=gray> disturbing </font><font size = 1, color=gray> and </font><font size = 1, color=gray> disappointing.<br </font><font size = 1, color=gray> /><br </font><font size = 1, color=gray> />I </font><font size = 1, color=gray> do </font><font size = 1, color=gray> now </font><font size = 1, color=gray> find </font><font size = 1, color=gray> any </font><font size = 1, color=gray> of </font><font size = 1, color=gray> the </font><font size = 1, color=gray> second </font><font size = 1, color=gray> and </font><font size = 1, color=gray> third </font><font size = 1, color=gray> season </font><font size = 1, color=gray> fun, </font><font size = 1, color=gray> they </font><font size = 1, color=gray> seem </font><font size = 1, color=gray> like </font><font size = 1, color=gray> a </font><font size = 1, color=gray> re-watch </font><font size = 1, color=gray> of </font><font size = 1, color=gray> some </font><font size = 1, color=gray> teens </font><font size = 1, color=gray> shows. </font><font size = 1, color=gray> I </font><font size = 1, color=gray> hat </font><font size = 1, color=gray> that </font><font size = 1, color=gray> garbage. </font><font size = 1, color=gray> The </font><font size = 1, color=gray> first </font><font size = 1, color=gray> season </font><font size = 1, color=gray> was </font><font size = 1, color=gray> very </font><font size = 1, color=gray> unique </font><font size = 1, color=gray> because </font><font size = 1, color=gray> it </font><font size = 1, color=gray> showed </font><font size = 1, color=gray> Sadie </font><font size = 1, color=gray> who </font><font size = 1, color=gray> loved </font><font size = 1, color=gray> science </font><font size = 1, color=gray> and </font><font size = 1, color=gray> animals </font><font size = 1, color=gray> and </font><font size = 1, color=gray> creatures. </font><font size = 1, color=gray> The </font><font size = 1, color=gray> first </font><font size = 1, color=gray> season </font><font size = 1, color=gray> was </font><font size = 1, color=gray> very </font><font size = 1, color=gray> entertaining. </font><font size = 1, color=gray> I </font><font size = 1, color=gray> mostly </font><font size = 1, color=gray> don't </font><font size = 1, color=gray> like </font><font size = 1, color=gray> the </font><font size = 1, color=gray> second </font><font size = 1, color=gray> season </font><font size = 1, color=gray> because </font><font size = 1, color=gray> of </font><font size = 1, color=gray> Ben. </font><font size = 1, color=gray> He </font><font size = 1, color=gray> annoys </font><font size = 1, color=gray> me </font><font size = 1, color=gray> and </font><font size = 1, color=gray> pisses </font><font size = 1, color=gray> the </font><font size = 1, color=gray> crap </font><font size = 1, color=gray> outta </font><font size = 1, color=gray> me. </font><font size = 1, color=gray> The </font><font size = 1, color=gray> plot </font><font size = 1, color=gray> in </font><font size = 1, color=gray> the </font><font size = 1, color=gray> second </font><font size = 1, color=gray> season </font><font size = 1, color=gray> also </font><font size = 1, color=gray> sucks </font><font size = 1, color=gray> and </font><font size = 1, color=gray> is </font><font size = 1, color=gray> just </font><font size = 1, color=gray> awful </font>"
      ],
      "text/plain": [
       "<utils.ColoredWeightedDoc at 0x7f69847ba4e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Best Classifier<b>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size = 1, color=gray> when </font><font size = 1, color=gray> this </font><font size = 1, color=gray> show </font><font size = 1, color=gray> first </font><font size = 1, color=gray> came </font><font size = 1, color=gray> to </font><font size = 1, color=gray> Disney, </font><font size = 1, color=gray> i </font><font size = 1, color=gray> love </font><font size = 1, color=gray> it </font><font size = 1, color=gray> started </font><font size = 1, color=gray> watching </font><font size = 1, color=gray> all </font><font size = 1, color=gray> the </font><font size = 1, color=gray> time. </font><font size = 1, color=gray> It </font><font size = 1, color=gray> quickly </font><font size = 1, color=gray> became </font><font size = 1, color=gray> one </font><font size = 1, color=gray> of </font><font size = 1, color=gray> my </font><font size = 1, color=gray> favorite </font><font size = 1, color=gray> Disney </font><font size = 1, color=gray> shows </font><font size = 1, color=gray> ever </font><font size = 1, color=gray> but </font><font size = 1, color=gray> this </font><font size = 1, color=gray> show </font><font size = 1, color=gray> somehow </font><font size = 1, color=gray> transformed </font><font size = 1, color=gray> into </font><font size = 1, color=gray> something </font><font size = 1, color=gray> that </font><font size = 1, color=gray> is </font><font size = 1, color=gray> disturbing </font><font size = 1, color=gray> and </font><font size = 1, color=gray> disappointing.<br </font><font size = 1, color=gray> /><br </font><font size = 1, color=gray> />I </font><font size = 1, color=gray> do </font><font size = 1, color=gray> now </font><font size = 1, color=gray> find </font><font size = 1, color=gray> any </font><font size = 1, color=gray> of </font><font size = 1, color=gray> the </font><font size = 1, color=gray> second </font><font size = 1, color=gray> and </font><font size = 1, color=gray> third </font><font size = 1, color=gray> season </font><font size = 1, color=gray> fun, </font><font size = 1, color=gray> they </font><font size = 1, color=gray> seem </font><font size = 1, color=gray> like </font><font size = 1, color=gray> a </font><font size = 1, color=gray> re-watch </font><font size = 1, color=gray> of </font><font size = 1, color=gray> some </font><font size = 1, color=gray> teens </font><font size = 1, color=gray> shows. </font><font size = 1, color=gray> I </font><font size = 1, color=gray> hat </font><font size = 1, color=gray> that </font><font size = 1, color=gray> garbage. </font><font size = 1, color=gray> The </font><font size = 1, color=gray> first </font><font size = 1, color=gray> season </font><font size = 1, color=gray> was </font><font size = 1, color=gray> very </font><font size = 1, color=gray> unique </font><font size = 1, color=gray> because </font><font size = 1, color=gray> it </font><font size = 1, color=gray> showed </font><font size = 1, color=gray> Sadie </font><font size = 1, color=gray> who </font><font size = 1, color=gray> loved </font><font size = 1, color=gray> science </font><font size = 1, color=gray> and </font><font size = 1, color=gray> animals </font><font size = 1, color=gray> and </font><font size = 1, color=gray> creatures. </font><font size = 1, color=gray> The </font><font size = 1, color=gray> first </font><font size = 1, color=gray> season </font><font size = 1, color=gray> was </font><font size = 1, color=gray> very </font><font size = 1, color=gray> entertaining. </font><font size = 1, color=gray> I </font><font size = 1, color=gray> mostly </font><font size = 1, color=gray> don't </font><font size = 1, color=gray> like </font><font size = 1, color=gray> the </font><font size = 1, color=gray> second </font><font size = 1, color=gray> season </font><font size = 1, color=gray> because </font><font size = 1, color=gray> of </font><font size = 1, color=gray> Ben. </font><font size = 1, color=gray> He </font><font size = 1, color=gray> annoys </font><font size = 1, color=gray> me </font><font size = 1, color=gray> and </font><font size = 1, color=gray> pisses </font><font size = 1, color=gray> the </font><font size = 1, color=gray> crap </font><font size = 1, color=gray> outta </font><font size = 1, color=gray> me. </font><font size = 1, color=gray> The </font><font size = 1, color=gray> plot </font><font size = 1, color=gray> in </font><font size = 1, color=gray> the </font><font size = 1, color=gray> second </font><font size = 1, color=gray> season </font><font size = 1, color=gray> also </font><font size = 1, color=gray> sucks </font><font size = 1, color=gray> and </font><font size = 1, color=gray> is </font><font size = 1, color=gray> just </font><font size = 1, color=gray> awful </font>"
      ],
      "text/plain": [
       "<utils.ColoredWeightedDoc at 0x7f69847ba550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = ctrl_clf.predict_proba(X_test) - best_clf.predict_proba(X_test)\n",
    "x = np.absolute(x[:,0])\n",
    "inds = np.argsort(x)\n",
    "i = inds[-1]\n",
    "\n",
    "display_html(\"<b>\"+'Probability Matrix'+\"<b>\", raw=True)\n",
    "print(ctrl_clf.predict_proba(X_test)[i]) \n",
    "print(best_clf.predict_proba(X_test)[i])\n",
    "display_html(\"<b>\"+'Control Classifier'+\"<b>\", raw=True)\n",
    "display(ColoredWeightedDoc(test_corpus[i], feature_names, np.multiply(X_test[i].todense(), ctrl_clf.get_weights()))) # dot product\n",
    "display_html(\"<b>\"+'Best Classifier'+\"<b>\", raw=True)\n",
    "display(ColoredWeightedDoc(test_corpus[i], feature_names, np.multiply(X_test[i].todense(), best_clf.get_weights())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
