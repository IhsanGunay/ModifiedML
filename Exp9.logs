Loading the imdb reviews data
Data loaded.
Extracting features from the training dataset using a sparse vectorizer
Feature extraction technique is CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=None, min_df=5,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None).
done in 8.495665550231934s
n_samples: 12500, n_features: 19271 

Number of validation sets is 3
Loading the dataset took 10.18s. 

Round:     0, error = 0.1454, code: 12
Training Round: 0,	Test accuracy is 0.813,	Cotrol accuracy is 0.813
Training Round: 2,	Test accuracy is 0.813,	Cotrol accuracy is 0.813
Training Round: 3,	Test accuracy is 0.813,	Cotrol accuracy is 0.813
Training Round: 4,	Test accuracy is 0.813,	Cotrol accuracy is 0.813
Training Round: 5,	Test accuracy is 0.813,	Cotrol accuracy is 0.813
Training Round: 6,	Test accuracy is 0.813,	Cotrol accuracy is 0.813
Training Round: 7,	Test accuracy is 0.813,	Cotrol accuracy is 0.813
Training Round: 8,	Test accuracy is 0.813,	Cotrol accuracy is 0.813
Training Round: 9,	Test accuracy is 0.813,	Cotrol accuracy is 0.813
Training Round: 10,	Test accuracy is 0.813,	Cotrol accuracy is 0.813
Experiment is done.
<class 'classifiers.TransparentMultinomialNB'> 

[1, 2, 3, 4, 5, 6, 7, 8, 9, 10] 

CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=None, min_df=5,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)
Number of samples used : 12499
Number of labels modified: 0
Traceback (most recent call last):
  File "Exp9.py", line 250, in <module>
    changes = changed_labels[:,0] - changed_labels[:,1]
IndexError: too many indices
